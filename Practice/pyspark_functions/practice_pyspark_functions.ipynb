{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/home/glue_user/spark/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/home/glue_user/spark/jars/slf4j-reload4j-1.7.36.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/home/glue_user/aws-glue-libs/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/home/glue_user/aws-glue-libs/jars/slf4j-reload4j-1.7.36.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/02/01 23:21:53 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+--------+-------------+----------+-------------------+-------------+------------+----------+-------------------+------+------+----------------------------------------+---+\n",
      "|Name   |Age|Salary  |City         |JoinDate  |Skills1            |Skills2      |Scores      |Phone     |Email              |Height|Weight|BinaryData                              |ID |\n",
      "+-------+---+--------+-------------+----------+-------------------+-------------+------------+----------+-------------------+------+------+----------------------------------------+---+\n",
      "|Alice  |30 |60000.5 |New York     |2020-01-15|[Python, SQL]      |[SQL, Java]  |[90, 85, 88]|null      |alice@example.com  |165.2 |60.5  |[41 6C 69 63 65 42 69 6E 61 72 79]      |1  |\n",
      "|Bob    |25 |50000.75|London       |2019-07-21|[Java, C++]        |[Python, C++]|[78, 80, 82]|1234567890|null               |170.4 |68.2  |[42 6F 62 42 69 6E 61 72 79]            |2  |\n",
      "|Charlie|35 |75000.0 |San Francisco|2018-05-10|[JavaScript, Scala]|[Scala, Rust]|[95, 92, 89]|0987654321|charlie@example.com|180.3 |75.1  |[43 68 61 72 6C 69 65 42 69 6E 61 72 79]|3  |\n",
      "+-------+---+--------+-------------+----------+-------------------+-------------+------------+----------+-------------------+------+------+----------------------------------------+---+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"PySparkExamples\").getOrCreate()\n",
    "\n",
    "# Define Schema\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, ArrayType, BinaryType, FloatType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"Name\", StringType(), True),\n",
    "    StructField(\"Age\", IntegerType(), True),\n",
    "    StructField(\"Salary\", FloatType(), True),\n",
    "    StructField(\"City\", StringType(), True),\n",
    "    StructField(\"JoinDate\", StringType(), True),  # Date stored as string\n",
    "    StructField(\"Skills1\", ArrayType(StringType()), True),\n",
    "    StructField(\"Skills2\", ArrayType(StringType()), True),\n",
    "    StructField(\"Scores\", ArrayType(IntegerType()), True),\n",
    "    StructField(\"Phone\", StringType(), True),\n",
    "    StructField(\"Email\", StringType(), True),\n",
    "    StructField(\"Height\", FloatType(), True),\n",
    "    StructField(\"Weight\", FloatType(), True),\n",
    "    StructField(\"BinaryData\", BinaryType(), True),\n",
    "    StructField(\"ID\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "# Sample Data\n",
    "data = [\n",
    "    (\"Alice\", 30, 60000.50, \"New York\", \"2020-01-15\", [\"Python\", \"SQL\"], [\"SQL\", \"Java\"], [90, 85, 88], None, \"alice@example.com\", 165.2, 60.5, b\"AliceBinary\", 1),\n",
    "    (\"Bob\", 25, 50000.75, \"London\", \"2019-07-21\", [\"Java\", \"C++\"], [\"Python\", \"C++\"], [78, 80, 82], \"1234567890\", None, 170.4, 68.2, b\"BobBinary\", 2),\n",
    "    (\"Charlie\", 35, 75000.00, \"San Francisco\", \"2018-05-10\", [\"JavaScript\", \"Scala\"], [\"Scala\", \"Rust\"], [95, 92, 89], \"0987654321\", \"charlie@example.com\", 180.3, 75.1, b\"CharlieBinary\", 3)\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data, schema=schema)\n",
    "df.show(truncate=False)\n",
    "\n",
    "# # ðŸ”¹ Numeric Functions\n",
    "# df.select(\"Name\", \"Age\", abs(df[\"Age\"]).alias(\"AbsoluteAge\")).show()\n",
    "# df.select(\"Name\", \"Salary\", ceil(df[\"Salary\"]).alias(\"CeilingSalary\")).show()\n",
    "# df.select(\"Name\", \"Age\", cbrt(df[\"Age\"]).alias(\"CubeRootAge\")).show()\n",
    "# df.select(\"Name\", \"Age\", acos(df[\"Age\"]/100).alias(\"AcosAge\")).show()\n",
    "# df.select(\"Name\", \"Age\", asin(df[\"Age\"]/100).alias(\"AsinAge\")).show()\n",
    "# df.select(\"Name\", \"Age\", atan(df[\"Age\"]/100).alias(\"AtanAge\")).show()\n",
    "# df.select(\"Name\", \"Height\", \"Weight\", atan2(df[\"Height\"], df[\"Weight\"]).alias(\"Atan2HeightWeight\")).show()\n",
    "\n",
    "# # ðŸ”¹ Array Functions\n",
    "# df.select(\"Name\", \"Skills1\", \"Skills2\", array_intersect(df[\"Skills1\"], df[\"Skills2\"]).alias(\"CommonSkills\")).show()\n",
    "# df.select(\"Name\", \"Scores\", array_max(df[\"Scores\"]).alias(\"MaxScore\")).show()\n",
    "# df.select(\"Name\", \"Scores\", array_min(df[\"Scores\"]).alias(\"MinScore\")).show()\n",
    "# df.select(\"Name\", \"Skills1\", array_join(df[\"Skills1\"], \", \").alias(\"SkillsAsString\")).show()\n",
    "# df.select(\"Name\", \"Skills1\", array_repeat(df[\"Skills1\"], 2).alias(\"RepeatedSkills\")).show()\n",
    "# df.select(\"Name\", \"Skills1\", array_sort(df[\"Skills1\"]).alias(\"SortedSkills\")).show()\n",
    "# df.select(\"Name\", \"Skills1\", \"Skills2\", arrays_zip(df[\"Skills1\"], df[\"Skills2\"]).alias(\"ZippedSkills\")).show()\n",
    "\n",
    "# # ðŸ”¹ String Functions\n",
    "# df.select(\"Name\", ascii(df[\"Name\"]).alias(\"ASCII_FirstChar\")).show()\n",
    "# df.select(\"Name\", base64(df[\"BinaryData\"]).alias(\"Base64Encoded\")).show()\n",
    "\n",
    "# # ðŸ”¹ Bitwise & Binary Functions\n",
    "# df.select(\"Name\", \"ID\", bin(df[\"ID\"]).alias(\"BinaryRepresentation\")).show()\n",
    "# df.select(\"Name\", \"ID\", bitwise_not(df[\"ID\"]).alias(\"BitwiseNotID\")).show()\n",
    "\n",
    "# # ðŸ”¹ Date Functions\n",
    "# df.select(\"Name\", \"JoinDate\", add_months(df[\"JoinDate\"], 3).alias(\"DateAfter3Months\")).show()\n",
    "\n",
    "# # ðŸ”¹ Aggregation Functions\n",
    "# df.groupBy(\"City\").agg(avg(df[\"Salary\"]).alias(\"AverageSalary\")).show()\n",
    "# df.groupBy(\"City\").agg(collect_list(df[\"Name\"]).alias(\"PeopleInCity\")).show()\n",
    "# df.groupBy(\"City\").agg(collect_set(df[\"Name\"]).alias(\"UniquePeopleInCity\")).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+--------+-------------+----------+-------------------+-------------+------------+----------+-------------------+------+------+--------------------+---+\n",
      "|   Name|Age|  Salary|         City|  JoinDate|            Skills1|      Skills2|      Scores|     Phone|              Email|Height|Weight|          BinaryData| ID|\n",
      "+-------+---+--------+-------------+----------+-------------------+-------------+------------+----------+-------------------+------+------+--------------------+---+\n",
      "|  Alice| 30| 60000.5|     New York|2020-01-15|      [Python, SQL]|  [SQL, Java]|[90, 85, 88]|      null|  alice@example.com| 165.2|  60.5|[41 6C 69 63 65 4...|  1|\n",
      "|    Bob| 25|50000.75|       London|2019-07-21|        [Java, C++]|[Python, C++]|[78, 80, 82]|1234567890|               null| 170.4|  68.2|[42 6F 62 42 69 6...|  2|\n",
      "|Charlie| 35| 75000.0|San Francisco|2018-05-10|[JavaScript, Scala]|[Scala, Rust]|[95, 92, 89]|0987654321|charlie@example.com| 180.3|  75.1|[43 68 61 72 6C 6...|  3|\n",
      "+-------+---+--------+-------------+----------+-------------------+-------------+------------+----------+-------------------+------+------+--------------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\"Name\", \"JoinDate\", add_months(df[\"2012-12-12\"], 3).alias(\"DateAfter3Months\")).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
